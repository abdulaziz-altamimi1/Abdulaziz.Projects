{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9120d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df.drop(['Unnamed: 0', 'id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check dataset\n",
    "print(\"The Shape:\",df.shape)\n",
    "print(\"The NULL values:\\n\",df.isnull().sum())\n",
    "print(\"Number of duplicated values\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of a DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Label encoder\n",
    "df_categorical = df.select_dtypes(include=['object'])\n",
    "enc = LabelEncoder()\n",
    "df_categorical = df_categorical.apply(enc.fit_transform)\n",
    "df.drop(df_categorical.columns, axis=1, inplace=True)\n",
    "df = pd.concat([df, df_categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffceca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "feature_cols = [\n",
    "    'Age', 'Flight Distance', 'Inflight wifi service',\n",
    "    'Ease of Online booking', 'Food and drink', 'Online boarding',\n",
    "    'Seat comfort', 'Inflight entertainment', 'On-board service',\n",
    "    'Leg room service', 'Baggage handling', 'Checkin service',\n",
    "    'Inflight service', 'Cleanliness', 'Customer Type',\n",
    "    'Type of Travel', 'Class'\n",
    "]\n",
    "X = df[feature_cols]\n",
    "y = df['satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913dbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network model \n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply early stopping \n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model \n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297eb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the model loss against the actual val_loss\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot(title=\"Cross-Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#compare the model accuracy against the actual val accuracy\n",
    "history_df[['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b957d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_labels)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
    "prec = metrics.precision_score(y_test, y_pred_labels)\n",
    "rec = metrics.recall_score(y_test, y_pred_labels)\n",
    "f1 = metrics.f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61720060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test evaluate \n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
